{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "# Определение модели Unet\n",
    "class CNA(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_nc, out_nc, 3, stride=stride, padding=1, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(out_nc)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, in_nc, inner_nc, out_nc, inner_block=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = CNA(in_nc, inner_nc, stride=2)\n",
    "        self.conv2 = CNA(inner_nc, inner_nc)\n",
    "        self.inner_block = inner_block\n",
    "        self.conv3 = CNA(inner_nc, inner_nc)\n",
    "        self.conv_cat = nn.Conv2d(inner_nc + in_nc, out_nc, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.shape\n",
    "\n",
    "        inner = self.conv1(x)\n",
    "        inner = self.conv2(inner)\n",
    "        if self.inner_block is not None:\n",
    "            inner = self.inner_block(inner)\n",
    "        inner = self.conv3(inner)\n",
    "\n",
    "        inner = F.upsample(inner, size=(h, w), mode='bilinear')\n",
    "\n",
    "        inner = torch.cat((x, inner), axis=1)\n",
    "        out = self.conv_cat(inner)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_nc=1, nc=32, out_nc=1, num_downs=6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cna1 = CNA(in_nc, nc)\n",
    "        self.cna2 = CNA(nc, nc)\n",
    "\n",
    "        unet_block = None\n",
    "        for i in range(num_downs-3):\n",
    "            unet_block = UnetBlock(8*nc, 8*nc, 8*nc, unet_block)\n",
    "        unet_block = UnetBlock(4*nc, 8*nc, 4*nc, unet_block)\n",
    "        unet_block = UnetBlock(2*nc, 4*nc, 2*nc, unet_block)\n",
    "        self.unet_block = UnetBlock(nc, 2*nc, nc, unet_block)\n",
    "\n",
    "        self.cna3 = CNA(nc, nc)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(nc, out_nc, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cna1(x)\n",
    "        out = self.cna2(out)\n",
    "        out = self.unet_block(out)\n",
    "        out = self.cna3(out)\n",
    "        out = self.conv_last(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Определение класса для загрузки данных\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_directory, masks_directory, transform=None):\n",
    "        self.images_directory = images_directory\n",
    "        self.masks_directory = masks_directory\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images_filenames = sorted(os.listdir(self.images_directory))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "        image = cv2.imread(os.path.join(self.images_directory, image_filename), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(os.path.join(self.masks_directory, image_filename), cv2.IMREAD_COLOR)[:, :, 0:1]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "            mask = np.transpose(mask, (2, 0, 1))\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Определение аугментаций для обучающего наборов данных\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=256, min_width=256),\n",
    "        A.RandomCrop(256, 256),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=256, min_width=256),\n",
    "        A.CenterCrop(256, 256),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_images_path = 'D:/pictures/'\n",
    "ds_masks_path = 'D:/masks/'\n",
    "\n",
    "# Создание экземпляра обучающего набора данных\n",
    "ds_train = MyDataset(ds_images_path, ds_masks_path, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Создание загрузчика данных для обучающего набора\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds_train, shuffle=True,\n",
    "    batch_size=batch_size, num_workers=0, drop_last=True\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Создание экземпляра модели UNet\n",
    "unet_model = Unet(in_nc=3, nc=32, out_nc=1, num_downs=5)\n",
    "unet_model = unet_model.to(device)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(unet_model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "# Цикл обучения модели\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm(train_loader)):\n",
    "        img, mask = sample\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = unet_model(img)\n",
    "        loss = loss_fn(pred, mask)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'{loss_val/len(train_loader)}\\t lr: {scheduler.get_last_lr()}')\n",
    "\n",
    "print('Обучение завершено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и преобразование нового изображения\n",
    "new_image = Image.open('D:/new/pic/00003.PNG')\n",
    "new_image_np = np.array(new_image)\n",
    "if len(new_image_np.shape) == 2:  \n",
    "    new_image_np = np.expand_dims(new_image_np, axis=2)\n",
    "    new_image_np = np.repeat(new_image_np, 3, axis=2)\n",
    "new_image_np = new_image_np.transpose(2, 0, 1)\n",
    "new_image_tensor = torch.from_numpy(new_image_np).unsqueeze(0).float()\n",
    "new_image_tensor = new_image_tensor.to(device)\n",
    "\n",
    "# Получение маски сегментации\n",
    "with torch.no_grad():\n",
    "    pred = unet_model(new_image_tensor)\n",
    "pred = F.sigmoid(pred).cpu().numpy()[0].transpose(1, 2, 0)\n",
    "\n",
    "# Преобразование маски в черно-белые цвета\n",
    "pred_gray = np.mean(pred, axis=2)\n",
    "pred_gray = np.repeat(pred_gray[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "# Визуализация исходного изображения и маски сегментации\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(new_image_np.transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pred_gray, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()  # Вывод всех подокон"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
